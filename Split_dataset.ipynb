{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "052bb807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07594be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a7b1c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# المسار الرئيسي لمجلدات الحروف الأصلية\n",
    "\n",
    "SRC_DIR = '../Dataset/ArASL_Database_54K_Final'  # مجلد الصور الأصلي\n",
    "DEST_DIR = './dataset_split'                    # مكان التقسيم\n",
    "VALID_EXT = {'.png', '.jpg', '.jpeg'}           # الامتدادات المسموحة\n",
    "\n",
    "\n",
    "\n",
    "# النسب\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.1\n",
    "assert abs((train_ratio + val_ratio + test_ratio) - 1.0) < 1e-6, \"The ratios must add up to 1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36411e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# تحقق من وجود المصدر\n",
    "assert os.path.exists(SRC_DIR) and os.path.isdir(SRC_DIR), f\"The folder does not exist: {os.path.abspath(SRC_DIR)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb71de4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# جمع الفئات (مجلدات فقط)\n",
    "classes = sorted([\n",
    "    d for d in os.listdir(SRC_DIR)\n",
    "    if os.path.isdir(os.path.join(SRC_DIR, d)) and not d.startswith('.')\n",
    "])\n",
    "assert classes, \"There are no categories in the Dataset\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56c5fc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letter ain       : Train=1691, Validation=211, Test=212\n",
      "Letter al        : Train=1074, Validation=134, Test=135\n",
      "Letter aleff     : Train=1337, Validation=167, Test=168\n",
      "Letter bb        : Train=1432, Validation=179, Test=180\n",
      "Letter dal       : Train=1307, Validation=163, Test=164\n",
      "Letter dha       : Train=1378, Validation=172, Test=173\n",
      "Letter dhad      : Train=1336, Validation=167, Test=167\n",
      "Letter fa        : Train=1564, Validation=195, Test=196\n",
      "Letter gaaf      : Train=1364, Validation=170, Test=171\n",
      "Letter ghain     : Train=1581, Validation=197, Test=199\n",
      "Letter ha        : Train=1273, Validation=159, Test=160\n",
      "Letter haa       : Train=1220, Validation=152, Test=154\n",
      "Letter jeem      : Train=1241, Validation=155, Test=156\n",
      "Letter kaaf      : Train=1419, Validation=177, Test=178\n",
      "Letter khaa      : Train=1285, Validation=160, Test=162\n",
      "Letter la        : Train=1396, Validation=174, Test=176\n",
      "Letter laam      : Train=1465, Validation=183, Test=184\n",
      "Letter meem      : Train=1412, Validation=176, Test=177\n",
      "Letter nun       : Train=1455, Validation=181, Test=183\n",
      "Letter ra        : Train=1327, Validation=165, Test=167\n",
      "Letter saad      : Train=1516, Validation=189, Test=190\n",
      "Letter seen      : Train=1310, Validation=163, Test=165\n",
      "Letter sheen     : Train=1205, Validation=150, Test=152\n",
      "Letter ta        : Train=1452, Validation=181, Test=183\n",
      "Letter taa       : Train=1470, Validation=183, Test=185\n",
      "Letter thaa      : Train=1412, Validation=176, Test=178\n",
      "Letter thal      : Train=1265, Validation=158, Test=159\n",
      "Letter toot      : Train=1432, Validation=179, Test=180\n",
      "Letter waw       : Train=1096, Validation=137, Test=138\n",
      "Letter ya        : Train=1377, Validation=172, Test=173\n",
      "Letter yaa       : Train=1034, Validation=129, Test=130\n",
      "Letter zay       : Train=1099, Validation=137, Test=138\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# إنشاء مجلدات التقسيم\n",
    "for split in ('train', 'val', 'test'):\n",
    "    for cls in classes:\n",
    "        dest_path = os.path.join(DEST_DIR, split, cls)\n",
    "        os.makedirs(dest_path, exist_ok=True)\n",
    "\n",
    "summary_train = summary_val = summary_test = summary_total = 0\n",
    "\n",
    "# بدء التقسيم\n",
    "for cls in classes:\n",
    "    src_path = os.path.join(SRC_DIR, cls)\n",
    "\n",
    "    # الصور فقط\n",
    "    images = [\n",
    "        img for img in os.listdir(src_path)\n",
    "        if os.path.isfile(os.path.join(src_path, img))\n",
    "        and os.path.splitext(img)[1].lower() in VALID_EXT\n",
    "    ]\n",
    "\n",
    "    random.shuffle(images)\n",
    "\n",
    "    n_total = len(images)\n",
    "    if n_total == 0:\n",
    "        print(f\"[warning] {cls} Contains no images — skipped\")\n",
    "        continue\n",
    "\n",
    "    n_train = int(train_ratio * n_total)\n",
    "    n_val   = int(val_ratio   * n_total)\n",
    "    n_test  = n_total - n_train - n_val\n",
    "\n",
    "    # دعم الفئات الصغيرة (إن أمكن)\n",
    "    if n_total >= 3:\n",
    "        if n_val == 0:  n_val = 1\n",
    "        if n_test == 0: n_test = 1\n",
    "        if n_train + n_val + n_test > n_total:\n",
    "            n_train = n_total - n_val - n_test\n",
    "\n",
    "    train_imgs = images[:n_train]\n",
    "    val_imgs   = images[n_train:n_train+n_val]\n",
    "    test_imgs  = images[n_train+n_val:]\n",
    "\n",
    "    # نسخ مع تخطي الموجود\n",
    "    for img_name in train_imgs:\n",
    "        src = os.path.join(src_path, img_name)\n",
    "        dst = os.path.join(DEST_DIR, 'train', cls, img_name)\n",
    "        if not os.path.exists(dst):\n",
    "            shutil.copy2(src, dst)\n",
    "\n",
    "    for img_name in val_imgs:\n",
    "        src = os.path.join(src_path, img_name)\n",
    "        dst = os.path.join(DEST_DIR, 'val', cls, img_name)\n",
    "        if not os.path.exists(dst):\n",
    "            shutil.copy2(src, dst)\n",
    "\n",
    "    for img_name in test_imgs:\n",
    "        src = os.path.join(src_path, img_name)\n",
    "        dst = os.path.join(DEST_DIR, 'test', cls, img_name)\n",
    "        if not os.path.exists(dst):\n",
    "            shutil.copy2(src, dst)\n",
    "\n",
    "    print(f\"Letter {cls:10}: Train={len(train_imgs)}, Validation={len(val_imgs)}, Test={len(test_imgs)}\")\n",
    "\n",
    "    summary_train += len(train_imgs)\n",
    "    summary_val   += len(val_imgs)\n",
    "    summary_test  += len(test_imgs)\n",
    "    summary_total += n_total\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77252bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SUMMARY ===\n",
      "Train: 43225 | Val: 5391 | Test: 5433 | TOTAL: 54049\n",
      "Partitioning is complete! \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== SUMMARY ===\")\n",
    "print(f\"Train: {summary_train} | Val: {summary_val} | Test: {summary_test} | TOTAL: {summary_total}\")\n",
    "print(\"Partitioning is complete! \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
